---
title: "Final Project"
author: "Rujia Xie"
date: "May 14, 2025"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Hmisc)
library(psych)
library(corrplot)
library(car)
library("sandwich")
library("lmtest")
library(caret)
```

# 1. Exploratory Data Analysis

```{r}
#Load in data downloaded from Kaggle
house_price <- read.csv("Boston-house-price-data.csv")
names(house_price)
```

This is a dataset called "Boston-house-price-data," which contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. Each observation in the Boston Housing dataset represents a single census tract (neighborhood) in the Boston area. The dataset includes various attributes describing the socioeconomic, environmental, and housing characteristics of these tracts, along with the median value of owner-occupied homes.

All variables in the dataset in order are:

- CRIM     per capita crime rate by town

- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.

- INDUS    proportion of non-retail business acres per town

- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)

- NOX      nitric oxides concentration (parts per 10 million)

- RM       average number of rooms per dwelling

- AGE      proportion of owner-occupied units built prior to 1940

- DIS      weighted distances to five Boston employment centres

- RAD      index of accessibility to radial highways

- TAX      full-value property-tax rate per $10,000

- PTRATIO  pupil-teacher ratio by town

- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town

- LSTAT    % lower status of the population

- MEDV     Median value of owner-occupied homes in $1000's

For this project, I will use MEDV as the target/outcome/dependent variable, and CRIM, RM, DIS, and RAD as the predictor/independent variables.

## 1.1 Identification of missing values and outliers
```{r}
sum(is.na(house_price))
```

## 1.2 Data cleaning and preprocessing steps

```{r}
house_price$CHAS <- factor(house_price$CHAS)
```

## 1.3 Summary statistics of variables
```{r}
describe(house_price)
```

## 1.4 Visualization of distributions and relationships
```{r}
hist(house_price$MEDV, breaks = 30, main = "Figure 1a. Histogram of Median Value of Homes")
hist(house_price$CRIM, breaks = 30, main = "Figure 1b. Histogram of Per Capita Crime Rate")
hist(house_price$RM, breaks = 30, main = "Figure 1c. Histogram of Rooms per Dwelling")
hist(house_price$DIS, breaks = 30, main = "Figure 1d. Histogram of Distance to Employment Centers")
hist(house_price$RAD, breaks = 30, main = "Figure 1e. Histogram of Accessibility to Highways")
```

Figures 1b and 1d indicate that CRIM and DIS are skewed to the right, which requires log transformation. Figure 1e presents the bimodal distribution of RAD, so it will be converted to a categorical variable with two levels: "low" (when $RAD \leq 15$) and "high" (when $RAD > 15$). Figures 2a-c present the distribution of the three transformed variables.

```{r}
house_price$RAD_cat <- ifelse(house_price$RAD <= 15, "low", "high")
house_price$CRIM_log <- log(house_price$CRIM)
house_price$DIS_log <- log(house_price$DIS)

hist(house_price$CRIM_log, breaks = 30, main = "Figure 2a. Histogram of Log(Per Capita Crime Rate)")
hist(log(house_price$DIS), breaks = 30, main = "Figure 2b. Histogram of Log(Distance to Employment Centers)")
barplot(table(house_price$RAD_cat), main = "Figure 2c. Bar Chart of Categorical RAD")
```

Since there are multiple predictors in the model, a heat map was drawn to check for multicollinearity among the outcome and continuous predictors. A red filling in the cell indicated a negative correlation, and a blue filling indicated a positive correlation. The P value for each correlation was also calculated.Correlations with p>.05 were crossed out in the matrix.

```{r}
house_subset <- house_price [c(14, 6, 16, 17 )]
house_correlation <-cor(house_subset, method="spearman", 
                           use="pairwise.complete.obs")


pmatrix <- cor.mtest(house_subset, conf.level = .95)
corrplot(title = "Figure 3. Heat Map of Predictors",
         house_correlation, p.mat = pmatrix$p, sig.level = .05,
         insig = "pch", pch.cex = 1.5, pch.col = "red", type = "lower",
         method="color", addCoef.col = "black", number.cex = 0.8, 
         tl.cex = 0.8, tl.srt = 45, tl.col = "black")
```

As shown in Figure 3, CRIM_log and DIS_log are significantly correlated with a coefficient of -0.74. Thus, CRIM_log was removed from the model.


# 2. Regression Assumptions Verification

```{r}
# Run the fitted linear regression model
house_model <- lm(MEDV ~ RM + DIS_log + RAD_cat,
           data = house_price)
summary(house_model)
```

## 2.1 Linearity assessment
```{r}
plot(house_model$fitted.values, house_price$MEDV,
     xlab = "fitted values", ylab = "observed values",
     main = "Figure 4. Linearity Check")
abline(a = 0, b = 1, col = "red")
```

Majority of the observations follow a linear trend.


## 2.2 Normality of residuals
```{r}
qqnorm(house_model$residuals, main = "Figure 5. Normality of Residuals")
qqline(house_model$residuals, col = "red")
```

Residuals of most observations follow a normal distribution, although outliers are present at both ends.


## 2.3 Check homoscedasticity (constant variance of residuals)
```{r}
plot(house_model$fitted.values, house_model$residuals,
     xlab = "fitted values", ylab = "residuals",
     main = "Figure 6. Homoscedasticity Check")
abline(h = 0, col = "red")
```

Heteroscedasticity is present in the residuals, since they are not randomly scattered around the red line in the plot.


## 2.4 check independence of observations

Because each row represents a unique census tract (neighborhood) in the Boston area, there are no repeated observations from the same subject. Thus, each observation is independent of the others.


## 2.5 Check multicollinearity
```{r}
vif(house_model)
```

All VIFs shown above are near 1, so multicollinearity is not present in the model.

# 3. Assumption Violation Handling

## 3.1 Apply appropriate transformations when assumptions are violated and document your approach to each violation

According to last section, the homoscedasticity assumption is violated, so we need to use heteroscedasticity-Consistent (HC) Standard Errors to address heteroscedasticity.

```{r}
sandwich1 <- coeftest(house_model, vcov = vcovHC(house_model, type = 'HC3'))
sandwich1
```

## 3.2 Compare models before and after corrections

This is the model summary before correction:

```{r}
summary(house_model)
```

This is the model summary after correction: 

```{r}
sandwich1
```

#####In other words, after correction, RAD becomes less significant, and RM's standard error increases from 0.40 to 0.69.


# 4. Variable Selection & Hypothesis Testing

## 4.1 Implement at least two different variable selection techniques

Step-wise regression was employed to find the model that accurately predicts the median value of owner-occupied homes (MEDV) in Boston, MA. Both forward and backward selection were conducted. We subset the house_price dataset so that the raw forms of the three transformed variables will not be included in the model.

```{r}
# Forward selection
null <- lm(MEDV ~ 1, data = house_price[-c(1, 8, 9)])
full <- lm(MEDV ~ ., data = house_price[-c(1, 8, 9)])
n <- nrow(house_price)

forward_model <- stats::step(null, 
                      scope = list(lower = null, upper = full),
                      direction = "forward", 
                      k = log(n))
```

```{r}
# Backward selection
backward_model <- stats::step(full, 
                      scope = list(lower = null, upper = full),
                      direction = "backward", 
                      k = log(n))
```

## 4.2 Perform hypothesis tests on coefficients

I will use the coefficients in the backward selection model as the example.

```{r}
plot(backward_model$fitted.values, backward_model$residuals,
     xlab = "fitted values", ylab = "residuals",
     main = "Figure 7. Homoscedasticity Check for Backward Selection Model")
abline(h = 0, col = "red")
```

As we can see from the plot, heteroscedasticity is present in the model, which prompts us to use the robust standard errors for hypothesis testing of coefficients.

```{r}
sandwich2 <- coeftest(backward_model, vcov = vcovHC(backward_model, type = 'HC3'))
sandwich2
```

As we can see from the summary above, all coefficients have a p-value smaller than 0.05. Therefore, we reject the null hypothesis that the coefficient is 0 for all of the coefficients in the backward_model.

## 4.3 Assess model performance with metrics (R², adjusted R², RMSE, etc.)

```{r}
summary(forward_model)
summary(backward_model)
```
```{r}
AIC(forward_model)
AIC(backward_model)
BIC(forward_model)
BIC(backward_model)
```

Based on the statistics above, backward_model should be preferred, as it has a higher r-squared and adjusted r-squared as well as a lower AIC and BIC than forward_model.

    
## 4.4 Validate your model using appropriate cross-validation techniques

```{r}
control <- trainControl(method = "cv", number = 10)
model_backward_cv <- train(MEDV ~ CHAS + NOX + RM + TAX + PTRATIO + B + LSTAT + 
    RAD_cat + DIS_log, data = house_price[-c(1, 8, 9)],
                  method = "lm",
                  trControl = control)
print(model_backward_cv)
```

For the backward_model, the 10-fold cross-validated RMSE is 4.729, which means the model predicts median housing values (MEDV) with an average error of about $4,729. An R² of 0.738 suggests that about 73.8% of the variance in MEDV is explained by the predictors. The model generalizes relatively well to new data.


# 5. Feature Impact Analysis

## 5.1 Quantify and interpret the impact of each feature on the target

For the linear regression model generated for the first objective, we have the following coefficients and interpretations:

-   Intercept: -33.9432 (p \< 0.001)

    The expected median value of owner-occupied homes when RM = 0, DIS_log = 0, and RAD_cat = "high" is -\$33,943.2, which serves as a baseline value.

-   RM: 8.3992 (p \< 0.001)

    Holding DIS_log and RAD_cat constant, a 1-unit increase in the average number of rooms per dwelling is associated with a \$8,399.2 increase in the expected median value of owner-occupied homes. This association is statistically significant.

-   DIS_log: -0.3439 (p = 0.57)

    The log of weighted distance to five Boston employment centers shows a non-significant effect on the expected median value of owner-occupied homes.

-   RAD_cat: 5.5449 (p \< 0.001)

    Holding RM and DIS_log constant, a low index of accessibility to radial highways ($RAD \leq 15$) is associated with a \$5,544.9 increase in the expected median value of owner-occupied homes compared to a high index of accessibility to radial highways (RAD \> 15). This association is statistically significant.

For the predictive model generated for the second objective, we have the following coefficients and interpretations:

-   Intercept: 48.8179 (p \< 0.001)

    The expected median value of owner-occupied homes (in \$1,000) when all predictors = 0, which serves as a baseline value.

-   CHAS: 2.9056 (p = 0.02)

    Holding everything else constant, being near the Charles River (CHAS = 1) is associated with a \$2,905.6 increase in the expected median value of owner-occupied homes. This association is statistically significant.

-   NOX: -24.2414 (p \< 0.001)

    Holding everything else constant, a 1-unit increase in the Nitric Oxide concentration (parts per 10 million) is associated with a \$24,241.4 decrease in the expected median value of owner-occupied homes. This association is statistically significant.

-   RM: 4.0350 (p \< 0.001)

    Holding everything else constant, a 1-unit increase in the average number of rooms per dwelling is associated with a \$4,035.0 increase in the expected median value of owner-occupied homes. This association is statistically significant.

-   TAX: -0.0108 (p \< 0.001)

    Holding everything else constant, a 1-unit increase in the full-value property-tax rate per \$10,000 is associated with a \$10.8 decrease in the expected median value of owner-occupied homes. This association is statistically significant.

-   PTRATIO: -1.0435 (p \< 0.001)

    Holding everything else constant, a 1-unit increase in the pupil-teacher ratio is associated with a \$1,043.5 decrease in the expected median value of owner-occupied homes. This association is statistically significant.

-   B: 0.0097 (p \< 0.001)

    Holding everything else constant, a 1-unit increase in the parabolically transformed value of African American resident proportion (the formula is 1000(Bk - 0.63)\^2, where Bk is the proportion of African American residents) is associated with a \$9.7 increase in the expected median value of owner-occupied homes. This association is statistically significant.

-   LSTAT: -0.5752 (p \< 0.001)

    Holding everything else constant, a 1-unit increase in the percentage of lower status of the population is associated with a \$575.2.0 decrease in the expected median value of owner-occupied homes. This association is statistically significant.

-   RAD_cat: -4.3153 (p \< 0.001)

    Holding everything else constant, a low index of accessibility to radial highways ($RAD \leq 15$) is associated with a \$4,315.3 decrease in the expected median value of owner-occupied homes compared to a high index of accessibility to radial highways ($RAD > 15$). This association is statistically significant.

-   DIS_log: -6.5110 (p \< 0.001)

    Holding everything else constant, a 1% increase in the weighted distance to five Boston employment centers is associated with a \$65.11 decrease in the expected median value of owner-occupied homes. This association is statistically significant.

## 5.2 Provide confidence intervals for significant coefficients

Due to the statistical significance of all variables in the backward_model, I will calculate the confidence interval for two of the significant coefficients. 

```{r}
t_star = qt((1-0.95)/2, df = 496, lower = F)
b1 = sandwich2["NOX", "Estimate"]
se1 = sandwich2["NOX", "Std. Error"]
lb1 = b1 - t_star*se1
ub1 = b1 + t_star*se1
lb1
ub1

b2 = sandwich2["CHAS1", "Estimate"]
se2 = sandwich2["CHAS1", "Std. Error"]
lb2 = b2 - t_star*se2
ub2 = b2 + t_star*se2
lb2
ub2
```


## 5.3 Explain the practical significance of your findings in the context of the dataset

This project does two things. First, it investigated the relationship between the median value of owner-occupied homes (MEDV) and the average number of rooms per dwelling (RM), the weighted distance to five Boston employment centers (DIS), and the index of accessibility to radial highways (RAD). Then, the project developed a predictive model that estimates the median value of owner-occupied homes (MEDV) in Boston, MA, using step-wise regression.

According to the first model, the median value of homes is positively associated with the number of rooms and negatively associated with accessibility. In the more comprehensive predictive model, the median value of homes is higher near the Charles River, with more rooms, and slightly with a higher parabolically transformed value of African American resident proportion. Conversely, home values decline with increased NOx pollution, higher property taxes, greater pupil-teacher ratios, a higher percentage of lower-status residents, and greater (log-transformed) distances from employment centers. While these findings offer insights into Boston's housing dynamics for policymakers and real estate professionals, it’s critical that such models are applied thoughtfully to avoid reinforcing systemic inequities.


#### Deliverables

GitHub Repository containing:

* All code (well-documented Rmd files)
* README.md with clear instructions on how to run your analysis
* Data folder (or instructions for accessing the data)
* Requirements.txt or environment.yml file


#### Final Report (PDF) containing:

* Introduction: dataset description and problem statement
* Methodology: techniques used and justification
* Results: findings from your analysis
* Discussion: interpretation of results and limitations
* Conclusion: summary and potential future work
* References: cite all sources used


## Evaluation Criteria
Your project will be evaluated based on:

* Correctness of statistical analysis and procedures
* Proper handling of regression assumptions
* Quality of variable selection and hypothesis testing
* Clarity of interpretation and insights
* Organization and documentation of code
* Professional presentation of findings
